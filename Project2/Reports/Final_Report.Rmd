---
title: "Project 2"
author: "Annie Thwing"
date: "11/01/2017"
output: pdf_document
fontsize: 11pt
geometry: margin=1in
---
\openup 1em

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sas7bdat)
library(VIM)
library(tableone)

dat <- read.sas7bdat("~/Documents/CU Denver/Fall_2017/Advanced_Data_Analysis/Project_2/vadata2.sas7bdat")
full_dat <- dat[,c("hospcode","sixmonth","proced","asa","bmi","albumin","death30")]
final <- read.table("~/Documents/CU Denver/Fall_2017/Advanced_Data_Analysis/Project_2/final.txt",header = T)

dat[which(dat$proced==2),] <- NA
dat$weight[which(dat$hospcode<17 & dat$sixmonth==39)] <- dat$weight[which(dat$hospcode<17 & dat$sixmonth==39)]*2.2
dat$bmi <- 703*(dat$weight/((dat$height)^2))
```

## Introduction

For this project we are determining whether or not certain VA hospitals have significantly higher or lower death rates among patients undergoing heart surgery than they are expected to.  We want to do this to be able to recommend which hospitals, if any, may need a site visit to either identify potential problems if their death rates are higher than expected, or to observe and learn from their practices if their death rates are lower than expected.  We are working with data that is simulated to represent data generated by the VA every six months.  This data would be generated every six months at the VA and would include information on all of the heart surgeries performed during that current six month period; information about the procedure type used (CABG or valve), height and weight of the patient, the patient's condition going into surgery, and the patients 30 day mortality outcome after surgery.  For this analysis we have information on the current six-month period, period 39, for 4,003 heart surgery patients at 44 different hospitals, along with three years of previous six-month periods.  We want to calculate the expected death rates per hospital for the current six month period, along with a measure of variance, and compare this expected death rate to the actual observed death rate at the current six month period for each hospital.

## Methods

In order to get a sense of the distribution of our dataset, we looked at initial descriptive statistics and plots of all of our variables.  This was done in order to ensure that we were working with the data that we thought we were, in the units that we were expecting.  An initial examination found a few characteristics of our dataset worth noting.  The first of these was that weight measurements from hospitals 1-17 during period 39 were not in the units we were expecting them to be in.  This was important because we would like to communicate with these hospitals that we would like weight measurements in lbs. and not kgs. in future reported datasets.  Next, we found that some hospitals had included patients that had undergone a procedure which we were not expecting to see data on.  After discussing this with our investigator, these individuals were removed from the dataset.  The final characteristic of this dataset worth mentioning was the large amount of missing data, specifically relating to the albumin variable, a measure of albumin (a protein made by the liver) in g/dL.  Since including albumin in our dataset would reduce our sample size by 13,241 subjects and it did not prove to be a significant covariate (p = 0.7239) when also adjusting for procedure, asa, and bmi, we elected to completely remove it as a variable from our analysis.

In order to get expected and observed rates for period 39 for each hospital, we first fit a logistic model in order to best predict thirty day mortality (death30) given condition at start of surgery (asa), heart surgery procedure used (proced), and body mass index (bmi).  BMI was used as a measure of health instead of weight and height, so that no multicollinearity issues were introduced by including both variables, since its calculation depends on both weight and height.  Of the remaining covariates, only those with complete cases were considered for our model, possible repurcussions of which we will discuss in our results section.  Although this reduced our dataset, it was not reduced by too much as we still had 24,618 measurements on 4,003 individuals we could include in our model.  We chose to fit a logistic model, as our outcome, thirty day mortality, was binary, and we used the data from every six-month period available in order to best fit our model.

This model was then used to predict the expected death rate for the latest six-month period for each hospital.  Predicted probabilites were calculated for every individual in the dataset this way, given their specific values of asa, proced, and BMI.  These predicted probabilites were then averaged over all of the individuals in each hospital to obtain an expected value for each hospital.  We felt comfortable using the mean, as the data did not appear to be too skewed, or suggest that another measure, such as the median, should be used instead.  Finally, the observed values for period 39 were calculated for each hospital by averaging the total number of observed deaths during the last six-month period over the number of subjects observed.

In order to obtain a measure of variation for our expected death rates per hospital, bootstrapping was used to calculate 2.5% and 97.5% quantile intervals for the expected death rate of each hospital.  This was done by creating a new sample, with replacement, from our full data set and using it to fit our new model.  Predicted probabilities were then calculated using the original data from period 39, and again grouped and averaged per hospital.  This was repeated 1000 times, after which the .025 and .975 quantiles of the predicted probabilites for each hospital were taken and used to be the upper and lower bounds of a 95% confidence interval.

## Results

As can be seen from our table one below, we have 43 hospitals with 4,003 individuals with complete information at the latest six-month period.  Of these individuals, 118 died within thirty days of surgery while 3885 were still alive.  Of the 4,003 individuals, 759 of them underwent valve surgery, while 3244 of them underwent the CABG procedure.  Of those that underwent valve surgery, 2.5% of them died, while 3% of those that underwent the CABG procedure died.  This does not suggest that procedure type is highly associated with our outcome.  ASA (or condition at start of surgery) does look to be associated with thirty day mortality, as 28.5% of patients with an ASA of 5 died within thirty days of surgery, compared to 0%, 1.6%, 1.9%, and 3.3% at each of the other respective levels.  Finally, BMI does not look like it is a strong indicator of thirty day mortality after surgery, as means between those in each group do not significantly differ once the standard deviation is also taken into account.

Including albumin as a covariate in the model for the set of individuals that had albumin as a recorded measure, did not prove it to be a valuable measure.  Albumin was not a significant predictor of death once other covariates were adjusted for, additionally the estimates of the other covariates were not affected by its inclusion in the model and the AIC's of the model without albumin and the model adjusting for albumin were identical.  Although it is up to the investigator to decide, we do not think that hospitals need to continue to collect measurements on albumin for each patient.

Even once we removed albumin as a covariate in our model, we had a substantial amount of missing data in our dataset, and inspection of the distribution of our missing data across the outcome causes us to be concerned that our estimates are biased. We are worried about having bias in our estimates as the distribution of asa, proced and BMI, do not appear consistent across our observed death after 30 days between the missing and the non missing in our full dataset.  We found that while those not missing BMI data had observed death rates of around 3%, those missing BMI data had observed death rates around 6.8%.  Additionally, those missing procedure data had death rates around 7.7% as compared to the 3.2% observed death rates from those not missing procedural data.  Finally, those missing asa data had death rates around 5.1% across all of our data while those not missing asa data had observed death rates around 3.2%.  This causes us to be concerned, as it may indicate a pattern of missingness in our data which in turn could be contributing to bias in our estimates of expected death rates per hospital.

```{r,echo=F,comment=NA}
# Look at distribution of missing data variables across the outcomes
bmi_missing <- sum(full_dat$death30[which(is.na(full_dat$bmi))])/length(full_dat$death30[which(is.na(full_dat$bmi))])
bmi_not_missing <- sum(full_dat$death30[which(!is.na(full_dat$bmi))])/length(full_dat$death30[which(!is.na(full_dat$bmi))])
cbind(bmi_missing,bmi_not_missing)

proced_missing <- sum(full_dat$death30[which(is.na(full_dat$proced))])/length(full_dat$death30[which(is.na(full_dat$proced))])
proced_not_missing <- sum(full_dat$death30[which(!is.na(full_dat$proced))])/length(full_dat$death30[which(!is.na(full_dat$proced))])
cbind(proced_missing,proced_not_missing)

asa_missing <- sum(full_dat$death30[which(is.na(full_dat$asa))])/length(full_dat$death30[which(is.na(full_dat$asa))])
asa_not_missing <- sum(full_dat$death30[which(!is.na(full_dat$asa))])/length(full_dat$death30[which(!is.na(full_dat$asa))])
cbind(asa_missing,asa_not_missing)
```

We are also worried about the pattern of missing data that we see in hospital 30, which has so much missing BMI data that its expected death rate could not be calculated for period 39.  We hope that this missing data is missing at random, however as the snapshot below shows, we are concerned that it is not as the observed death rates of hospital 30 over all of the time points, and also just during the last month both look higher than that of the other hospitals.  However, since we are not able to calculate expected death rate for hospital 30 due to the missing BMI data, we do not know if this is out of the ordinary.  We would like to request that hospital 30 provide more complete information so that we are able to calculate their expected death rate in the future.

```{r, echo=FALSE,comment=NA}
observed.total <- tapply(dat$death30, dat$hospcode, mean,simplify = T)
observed.39 <- tapply(dat$death30[which(dat$sixmonth==39)], dat$hospcode[which(dat$sixmonth==39)], mean,simplify = T)
obs <- cbind(observed.total,observed.39,final$observed)[27:33,]
colnames(obs) <- c("total observed","obs at 39 months","expected")
print(obs)
```



Finally, we can see from our results in the table below that 7 hospitals have observed death rates within the range that we expect, 16 hospitals have death rates greater than 20% above their expected death rate, 20 hospitals have death rates more than 20% below their expected death rate, and 1 hospital does not have enough information to draw conclusions about.

## Conclusions

In conclusion, we can see that hospitals 3, 7, 12, 13, 17, 21, 23, 24, 26, 28, 31, 34, 35, 37, 39, and 41 may need to be visited as their death rates look to be significantly higher than what we would expect.  Additionally, hospitals 1, 2, 5, 6,  9, 10, 11, 14, 16, 18, 19, 20, 27, 29, 32, 33, 36, 38, 42, and 44 could be checked out to see what they are doing to keep their death rate significantly below what would be expected from them.  Hospitals 4, 8, 15, 22, 25, 40, and 43 all have death rates in the range that we would expect so we do not feel that we need to follow up with them.  Hospital 30 should definitely be followed up with, both to request non missing BMI data in the future, and also because the observed death rates that we do see from them are a cause of concern.  
Care should be taken in interpreting the estimates of expected death rates as they are possibly biased downward, as the distribution of the missing data looks like it is different from the distribution of non-missing data.

Finally, as was previously noted in the results section, albumin does not appear to be a statistically interesting covariate to collect for this analysis, so we do not think that it needs to be collected in the future for this dataset.

## Reproducible Research

https://github.com/BIOS6623-UCD/bios6623-athwing/tree/master/Project2

## Tables

Table One for Period 39:

```{r,echo=FALSE,comment=NA}
dat <- dat[,c("hospcode","sixmonth","proced","asa","bmi","death30")]
dat <- na.omit(dat)
dat <- dat[which(dat$sixmonth==39),]

t1 <- CreateTableOne(vars = c("proced","asa","bmi","death30"),strata = "death30", data = dat,
               factorVars = c("proced","asa","death30"))
print(t1, showAllLevels = T)
```

Missing Data:

```{r , echo=FALSE,comment=NA}
aggr(full_dat, prop = F, numbers = T,combined=F,sortVars=T)
```

Final Hospital Table:

```{r , echo=FALSE,comment=NA}
print(final)
```

Expected vs. Observed Death Rate:

```{r , echo=FALSE,comment=NA}
plot(seq(1:44),final$observed,xlab="Hospitals",ylab="Death Rate",main="Expected vs Observed Death Rate",col=2,pch=1)
points(seq(1:44),final$expected,col=1,pch=1)
legend(0,.135,c("Obs","Exp"),col=c(2,1),pch=c(1,1))
```




